#!/usr/bin/python
# -*- coding: utf-8 -*-

from bs4 import BeautifulSoup
import re

html_doc = """
<html><head><title>The Dormouse's story</title></head>
<body>
<p class="title"><b>The Dormouse's story</b></p>

<p class="story">Once upon a time there were three little sisters; and their names were
<a href="http://example.com/elsie" class="sister" id="link1">Elsie</a>,
<a href="http://example.com/lacie" class="sister" id="link2">Lacie</a> and
<a href="http://example.com/tillie" class="sister" id="link3">Tillie</a>;
<a href="http://example.com/tillie" class="bro" id="link3">Alex</a>;
and they lived at the bottom of a well.</p>

<p class="story">...</p>

"""
soup = BeautifulSoup(html_doc)
############################################
#                                          #
#           Basic Use                      #
#                                          #
############################################
#print soup.title

#print type(soup.title)

#print soup.title.name

#print soup.title.string

#print soup.p

"""
atag = soup.a

print 'atag:',atag
print 'type(atag):',type(atag)
aText = atag.get_text()
aText2 = atag.string
aText3 = atag['class']

print 'aText = atag.get_text()'
print 'type(aText):',type(aText)
print 'aText:',aText

print '\naText2 = atag.string'
print 'type(aText2):',type(aText2)
print 'aText2:',aText2

print "\naText3 = atag['class']"
print 'type(aText3):',type(aText3)
print 'aText3:',aText3

"""

#print atag.name

#print atag.attrs

#print atag.get_text()

'''
allLink = soup.find_all('a')

for link in allLink:
    lText = link.get_text()
#    print lText
    lClass = link['class']
    print lClass
#    lClass2 = link.get('class')
#    print lClass2
    if (lClass==['sister']):
        print 'sister:',lText
'''
#print soup.find_all('a')

#print soup.find(id='link3')

#print soup.get_text()

'''
for link in soup.find_all('a'):
    print(link.get('href'))
   # http://example.com/elsie
   # http://example.com/lacie
   # http://example.com/tillie
'''

############################################
#          
#       .contents 和 .children 
#   tag的 .contents 属性可以将tag的子节点以列表的方式输出:
#          
#           
############################################
'''
p_tag = soup.find_all('p')
print 'p_tag type:',type(p_tag)
print 'len(p_tag):',len(p_tag)
count = 1
for ptag in p_tag:
    print 'type(ptag):',type(ptag)
    print 'ptag%d:'%count,ptag
    ptag_contents = ptag.contents
    raw_input('Show .contents')
    print 'ptag_contents type:',type(ptag.contents)
    print 'ptag_contents:',ptag.contents
    for content in ptag_contents:
        print 'content type:',type(content)
        print 'content:',content

    ptag_children = ptag.children
    raw_input('Show .children')
    print 'ptag_children type:',type(ptag.children)
    print 'ptag_children:',ptag.children

    raw_input('Next')
    count += 1
'''

############################################
#          
#       .strings 和 stripped_strings
#   如果tag中包含多个字符串 [2] ,可以使用 .strings 来循环获取
#   输出的字符串中可能包含了很多空格或空行,
#                使用 .stripped_strings 可以去除多余空白内容        
#           
############################################
'''
strs = soup.get_text()
strings = soup.strings
stripstr = soup.stripped_strings

print 'strs = soup.get_text()'
print 'strs type:',type(strs)
print 'strs:',strs

print 'strings = soup.strings'
print 'strings type:',type(strings)
print 'strings:',strings
for string in strings:
    print 'string type:',type(string)
    print 'string:',string
    raw_input('Next')

print 'stripstr = soup.stripped_strings'
print 'stripstr type:',type(stripstr)
print 'stripstr:',stripstr
for string in stripstr:
    print 'string type:',type(string)
    print 'string:',string
    raw_input('Next')
'''



############################################
#          
#       过滤器 
#   过滤器贯穿整个搜索的API.过滤器可以被用在tag的name中,
#               节点的属性中,字符串中或他们的混合中.
#           
#  1.字符串 2.正则表达式 3.列表 4.True 5.方法           
#
############################################

#1.字符串
#最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的<b>标签:
'''
print soup.find_all('b')
#[<b>The Dormouse's story</b>]
'''

#2.正则表达式
#如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示<body>和<b>标签都应该被找到
'''
for tag in soup.find_all(re.compile('^b')):
    print tag.name
#body
#b
'''

#3.列表
#如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有<a>标签和<b>标签:
'''
for tag in soup.find_all(['a','b']):
    print '#',tag.name
# b
# a
# a
# a
# a
'''

#4.True
#True 可以匹配任何值,下面代码查找到所有的tag,但是不会返回字符串节点

for tag in soup.find_all('True')
    print '#',tag.name
    



